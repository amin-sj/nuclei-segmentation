{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qMrCzY5UFSw"
      },
      "source": [
        "# Train U-Net 3+ with MoNuSeg dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2lxyy4JgQB_"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkvEVj1DgUwU"
      },
      "outputs": [],
      "source": [
        "!cat /proc/cpuinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNP2A-Dcjc6O"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcpa5mbeK3dk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7guJCJRsK7MW"
      },
      "outputs": [],
      "source": [
        "%cd drive/MyDrive/nuclei_segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRuQXwqXJhHJ"
      },
      "outputs": [],
      "source": [
        "# https://github.com/dovahcrow/patchify.py\n",
        "!pip install patchify"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0SwqgoBK0GL"
      },
      "source": [
        "## Make validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LKl6qvnLM4K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMrJsiMDLcpA"
      },
      "outputs": [],
      "source": [
        "def create_path(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWvuYRd2LPhn"
      },
      "outputs": [],
      "source": [
        "train_dir = \"dataset/monuseg/stain_normalized/train\"\n",
        "val_dir = \"dataset/monuseg/stain_normalized/validation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpCzs_rmLdeQ"
      },
      "outputs": [],
      "source": [
        "def make_validation_set(val_dir, train_dir, val_size=6, seed=42, fold=None):\n",
        "\n",
        "    create_path(val_dir)\n",
        "    create_path(os.path.join(val_dir, \"tissue_images\"))\n",
        "    create_path(os.path.join(val_dir, \"binary_masks\"))\n",
        "    create_path(os.path.join(val_dir, \"instance_masks\"))\n",
        "    create_path(os.path.join(val_dir, \"modified_masks\"))\n",
        "    \n",
        "    for j in sorted(glob.glob(os.path.join(val_dir, \"tissue_images\", \"*\"))):\n",
        "        try:\n",
        "            shutil.move(j, os.path.join(train_dir, \"tissue_images\"))\n",
        "            shutil.move(j.replace(\"tissue_images\", \"binary_masks\").replace(\"tif\", \"png\"), \n",
        "                        os.path.join(train_dir, \"binary_masks\"))\n",
        "            shutil.move(j.replace(\"tissue_images\", \"instance_masks\").replace(\"tif\", \"npy\"), \n",
        "                        os.path.join(train_dir, \"instance_masks\"))\n",
        "            shutil.move(j.replace(\"tissue_images\", \"modified_masks\").replace(\"tif\", \"png\"), \n",
        "                        os.path.join(train_dir, \"modified_masks\"))\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    images_lst = sorted(glob.glob(os.path.join(train_dir, \"tissue_images\", \"*\")))\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(images_lst)\n",
        "    if fold is None:\n",
        "        random.seed(seed)\n",
        "        val_lst = random.sample(images_lst, val_size)\n",
        "    else:\n",
        "        val_lst = images_lst[(fold*val_size)-val_size: fold*val_size]\n",
        "        \n",
        "\n",
        "    for i in val_lst:\n",
        "        shutil.move(i, os.path.join(val_dir, \"tissue_images\"))\n",
        "        shutil.move(i.replace(\"tissue_images\", \"binary_masks\").replace(\"tif\", \"png\"), \n",
        "                    os.path.join(val_dir, \"binary_masks\"))\n",
        "        shutil.move(i.replace(\"tissue_images\", \"instance_masks\").replace(\"tif\", \"npy\"), \n",
        "                    os.path.join(val_dir, \"instance_masks\"))\n",
        "        shutil.move(i.replace(\"tissue_images\", \"modified_masks\").replace(\"tif\", \"png\"), \n",
        "                    os.path.join(val_dir, \"modified_masks\"))\n",
        "        \n",
        "    print(f\"Validation list: {[os.path.basename(i) for i in val_lst]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e_pPZeWOXFA"
      },
      "outputs": [],
      "source": [
        "make_validation_set(val_dir, train_dir, val_size=6, fold=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spZeuYqGPbOR"
      },
      "source": [
        "## read the tissue images & GTs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N63nSLT5O6za"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from patchify import patchify, unpatchify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJbxgUwmj0-Z"
      },
      "outputs": [],
      "source": [
        "print(cv2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfyJ4CLUPBeV"
      },
      "outputs": [],
      "source": [
        "train_dir = \"dataset/monuseg/stain_normalized/train/tissue_images\"\n",
        "train_maskdir = \"dataset/monuseg/stain_normalized/train/binary_masks\"\n",
        "train_mask2dir = \"dataset/monuseg/stain_normalized/train/modified_masks\"\n",
        "\n",
        "val_dir   = \"dataset/monuseg/stain_normalized/validation/tissue_images\"\n",
        "val_maskdir = \"dataset/monuseg/stain_normalized/validation/binary_masks\"\n",
        "val_mask2dir = \"dataset/monuseg/stain_normalized/validation/modified_masks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUDndE1dPV_c"
      },
      "outputs": [],
      "source": [
        "W = 1024\n",
        "H = 1024\n",
        "\n",
        "patch_size = (256, 256, 3)\n",
        "all_img_patches = []\n",
        "for x in tqdm(sorted(glob.glob(os.path.join(train_dir, \"*\"))), total=len(os.listdir(train_dir))):\n",
        "    single_img = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "    single_img = cv2.cvtColor(single_img, cv2.COLOR_BGR2RGB)\n",
        "    single_img = cv2.resize(single_img, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "    # patchify\n",
        "    single_img_patches = patchify(single_img, patch_size=patch_size, step=128)\n",
        "    # squeeze\n",
        "    single_img_patches = np.squeeze(single_img_patches)\n",
        "\n",
        "    for i in range(single_img_patches.shape[0]):\n",
        "        for j in range(single_img_patches.shape[1]):\n",
        "            all_img_patches.append(single_img_patches[i, j])\n",
        "    \n",
        "train_images = np.array(all_img_patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2gfdNtxPkhw"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyCid9IcPlyK"
      },
      "outputs": [],
      "source": [
        "all_img_patches = []\n",
        "for x in tqdm(sorted(glob.glob(os.path.join(val_dir, \"*\"))), total=len(os.listdir(val_dir))):\n",
        "    single_img = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "    single_img = cv2.cvtColor(single_img, cv2.COLOR_BGR2RGB)\n",
        "    single_img = cv2.resize(single_img, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "    # patchify\n",
        "    single_img_patches = patchify(single_img, patch_size=patch_size, step=128)\n",
        "    # squeeze\n",
        "    single_img_patches = np.squeeze(single_img_patches)\n",
        "\n",
        "    for i in range(single_img_patches.shape[0]):\n",
        "        for j in range(single_img_patches.shape[1]):\n",
        "            all_img_patches.append(single_img_patches[i, j])\n",
        "\n",
        "val_images = np.array(all_img_patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXX6QqKAP4Zi"
      },
      "outputs": [],
      "source": [
        "val_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVsn7JEIP5cI"
      },
      "outputs": [],
      "source": [
        "all_mask_patches = []\n",
        "for x in tqdm(sorted(glob.glob(os.path.join(train_maskdir, \"*\"))), total=len(os.listdir(train_maskdir))):\n",
        "    single_mask = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
        "    single_mask = cv2.resize(single_mask, (W, H), interpolation=cv2.INTER_NEAREST)\n",
        "    # patchify\n",
        "    single_mask_patches = patchify(single_mask, patch_size=(256, 256), step=128)\n",
        "    # squeeze\n",
        "    single_mask_patches = np.squeeze(single_mask_patches)\n",
        "\n",
        "    for i in range(single_mask_patches.shape[0]):\n",
        "        for j in range(single_mask_patches.shape[1]):\n",
        "            all_mask_patches.append(single_mask_patches[i, j])\n",
        "\n",
        "train_masks = np.array(all_mask_patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43ERJyE_QH1V"
      },
      "outputs": [],
      "source": [
        "train_masks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkOkN8NIQI5W"
      },
      "outputs": [],
      "source": [
        "all_mask_patches = []\n",
        "for x in tqdm(sorted(glob.glob(os.path.join(val_maskdir, \"*\"))), total=len(os.listdir(val_maskdir))):\n",
        "    single_mask = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
        "    single_mask = cv2.resize(single_mask, (W, H), interpolation=cv2.INTER_NEAREST)\n",
        "    # patchify\n",
        "    single_mask_patches = patchify(single_mask, patch_size=(256, 256), step=128)\n",
        "    # squeeze\n",
        "    single_mask_patches = np.squeeze(single_mask_patches)\n",
        "\n",
        "    for i in range(single_mask_patches.shape[0]):\n",
        "        for j in range(single_mask_patches.shape[1]):\n",
        "            all_mask_patches.append(single_mask_patches[i, j])\n",
        "\n",
        "val_masks = np.array(all_mask_patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILL2tG8pQMD3"
      },
      "outputs": [],
      "source": [
        "val_masks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-jFoL9jQM4l"
      },
      "outputs": [],
      "source": [
        "all_mask_patches = []\n",
        "for x in tqdm(sorted(glob.glob(os.path.join(train_mask2dir, \"*\"))), total=len(os.listdir(train_mask2dir))):\n",
        "    single_mask = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
        "    single_mask = cv2.resize(single_mask, (W, H), interpolation=cv2.INTER_NEAREST)\n",
        "    # patchify\n",
        "    single_mask_patches = patchify(single_mask, patch_size=(256, 256), step=128)\n",
        "    # squeeze\n",
        "    single_mask_patches = np.squeeze(single_mask_patches)\n",
        "\n",
        "    for i in range(single_mask_patches.shape[0]):\n",
        "        for j in range(single_mask_patches.shape[1]):\n",
        "            # mask_with_boarders = generate_boarder(single_mask_patches[i, j])\n",
        "            all_mask_patches.append(single_mask_patches[i, j])\n",
        "\n",
        "train_masks2 = np.array(all_mask_patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrBDQrF3QPwd"
      },
      "outputs": [],
      "source": [
        "train_masks2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIgmGmtcQT1u"
      },
      "outputs": [],
      "source": [
        "all_mask_patches = []\n",
        "for x in tqdm(sorted(glob.glob(os.path.join(val_mask2dir, \"*\"))), total=len(os.listdir(val_mask2dir))):\n",
        "    single_mask = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
        "    single_mask = cv2.resize(single_mask, (W, H), interpolation=cv2.INTER_NEAREST)\n",
        "    # patchify\n",
        "    single_mask_patches = patchify(single_mask, patch_size=(256, 256), step=128)\n",
        "    # squeeze\n",
        "    single_mask_patches = np.squeeze(single_mask_patches)\n",
        "\n",
        "    for i in range(single_mask_patches.shape[0]):\n",
        "        for j in range(single_mask_patches.shape[1]):\n",
        "            # mask_with_boarders = generate_boarder(single_mask_patches[i, j])\n",
        "            all_mask_patches.append(single_mask_patches[i, j])\n",
        "\n",
        "val_masks2 = np.array(all_mask_patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUSpkjxnQVzm"
      },
      "outputs": [],
      "source": [
        "val_masks2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au_Cw7npQX-p"
      },
      "outputs": [],
      "source": [
        "# sanity check\n",
        "rnd = np.random.randint(len(train_images))\n",
        "# rnd = 222\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
        "[axi.set_axis_off() for axi in ax.ravel()]\n",
        "\n",
        "ax[0].imshow(train_images[rnd])\n",
        "ax[0].set_title(\"Tissue Image\")\n",
        "\n",
        "ax[1].imshow(train_masks[rnd])\n",
        "ax[1].set_title(\"Mask\")\n",
        "\n",
        "# ax[2].imshow(train_images[rnd])\n",
        "ax[2].imshow(train_masks2[rnd])\n",
        "ax[2].set_title(\"Mask2\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn5BQJI4QYuf"
      },
      "source": [
        "## One-hot encoding the modified masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVRjk1hjQjcw"
      },
      "outputs": [],
      "source": [
        "# train masks\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "n, h, w = train_masks.shape\n",
        "train_masks_reshaped = train_masks2.reshape(-1,)\n",
        "train_masks_reshaped_encoded = label_encoder.fit_transform(train_masks_reshaped)\n",
        "train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n",
        "\n",
        "n_classes = 3\n",
        "train_masks_cat = to_categorical(train_masks_encoded_original_shape, num_classes=n_classes)\n",
        "train_masks_cat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09zsQ6T2QrDS"
      },
      "outputs": [],
      "source": [
        "# val masks\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "n, h, w = val_masks.shape\n",
        "val_masks_reshaped = val_masks2.reshape(-1,)\n",
        "val_masks_reshaped_encoded = label_encoder.fit_transform(val_masks_reshaped)\n",
        "val_masks_encoded_original_shape = val_masks_reshaped_encoded.reshape(n, h, w)\n",
        "\n",
        "n_classes = 3\n",
        "val_masks_cat = to_categorical(val_masks_encoded_original_shape, num_classes=n_classes)\n",
        "val_masks_cat.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVBMAy7EREoG"
      },
      "source": [
        "## Data augmentation using albumentations library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yUdZajtQvwz"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from keras.utils import Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_t-im4zkMDt"
      },
      "outputs": [],
      "source": [
        "print(A.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLKh8vZHRLpf"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, images, masks, masks_cat, augmentations=None, batch_size=8, img_size=256, n_channels=3, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "        self.masks_cat = masks_cat\n",
        "\n",
        "        self.img_size = img_size\n",
        "        \n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augmentations\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indices of the batch\n",
        "        indices = self.indices[index * self.batch_size: min((index + 1) * self.batch_size, len(self.images))]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.data_generation(indices)\n",
        "        y1 = y[0]\n",
        "        y2 = y[1]\n",
        "\n",
        "        if self.augment is None:\n",
        "            return X, [np.array(y1), np.array(y2)]\n",
        "        else:            \n",
        "            im, mask1, mask2 = [], [], []   \n",
        "            for x, y1, y2 in zip(X, y1, y2):\n",
        "                augmented = self.augment(image=x, mask1=y1, mask2=y2)\n",
        "                im.append(augmented['image'])\n",
        "                mask1.append(augmented['mask1'])\n",
        "                mask2.append(augmented['mask2'])\n",
        "\n",
        "            return np.array(im), [np.array(mask1), np.array(mask1), np.array(mask1), np.array(mask1), np.array(mask1),\n",
        "                                  np.array(mask2), np.array(mask2), np.array(mask2), np.array(mask2), np.array(mask2),]\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indices after each epoch'\n",
        "        self.indices = np.arange(len(self.images))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def data_generation(self, indices):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((len(indices), self.img_size, self.img_size, self.n_channels))\n",
        "        y1 = np.empty((len(indices), self.img_size, self.img_size, 1))\n",
        "        y2 = np.empty((len(indices), self.img_size, self.img_size, 3)) # 3 classes (Nuclei, Border, Background)\n",
        "        # Generate data\n",
        "        for n, i in enumerate(indices):\n",
        "            X[n] = self.images[i]\n",
        "            y1[n] = (self.masks[i]/255.)[..., np.newaxis]\n",
        "            y2[n] = self.masks_cat[i]\n",
        "\n",
        "        return np.uint8(X), [np.float32(y1), np.float32(y2)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNrD-xJTRYqj"
      },
      "outputs": [],
      "source": [
        "AUGMENTATIONS_TRAIN = A.Compose([\n",
        "    A.Rotate(limit=360, p=0.5),\n",
        "    A.OneOf([\n",
        "        A.HorizontalFlip(),\n",
        "        A.VerticalFlip(),\n",
        "        ], p=0.5),\n",
        "    A.OneOf([\n",
        "        A.RandomBrightnessContrast(),\n",
        "        A.RandomGamma(),\n",
        "        A.GaussNoise()\n",
        "         ], p=0.3),\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
        "        # A.ElasticTransform(alpha=3, sigma=150, alpha_affine=150),\n",
        "        # A.ElasticTransform(),\n",
        "        A.Affine(translate_percent=0.2, shear=30, mode=cv2.BORDER_CONSTANT),\n",
        "        A.GridDistortion(),\n",
        "        A.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n",
        "        ], p=0.3),\n",
        "    A.OneOf([\n",
        "        A.RGBShift(r_shift_limit=40, g_shift_limit=40,  b_shift_limit=40),\n",
        "        A.ColorJitter(hue=0.1),\n",
        "        A.Blur(blur_limit=3)\n",
        "        ], p=0.3),\n",
        "    A.ToFloat(max_value=255)\n",
        "], p=1,\n",
        "additional_targets={'image': 'image', 'mask1': 'mask', 'mask2':'mask'})\n",
        "\n",
        "AUGMENTATIONS_VAL = A.Compose([\n",
        "    A.ToFloat(max_value=255)\n",
        "], p=1,\n",
        "additional_targets={'image': 'image', 'mask1': 'mask', 'mask2':'mask'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sahhqd3vRjCP"
      },
      "source": [
        "### Testing data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8-9L49JRf7C"
      },
      "outputs": [],
      "source": [
        "# Single tissue image with 256*256 tiles (50% overlap between tiles) without augmentation\n",
        "a = DataGenerator(train_images, train_masks, train_masks_cat, batch_size=49, augmentations=None, shuffle=False)\n",
        "images, masks = a.__getitem__(0)\n",
        "\n",
        "max_images = 49\n",
        "grid_width = 7\n",
        "grid_height = int(max_images / grid_width)\n",
        "fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width*2, grid_height*2))\n",
        "\n",
        "for i,(im, mask1, mask2) in enumerate(zip(images, masks[0], masks[1])):\n",
        "    ax = axs[int(i / grid_width), i % grid_width]\n",
        "    ax.imshow(im)\n",
        "    # ax.imshow(mask1.squeeze(), alpha=0.4)\n",
        "    ax.imshow(mask2, alpha=0.4)\n",
        "    ax.axis('off')\n",
        "\n",
        "print(mask1.shape)\n",
        "print(mask2.shape)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ekm-jFneR4hn"
      },
      "outputs": [],
      "source": [
        "# Same tissue image with augmentations\n",
        "a = DataGenerator(train_images, train_masks, train_masks_cat, batch_size=49, augmentations=AUGMENTATIONS_TRAIN, shuffle=False)\n",
        "images, masks = a.__getitem__(0)\n",
        "\n",
        "max_images = 49\n",
        "grid_width = 7\n",
        "grid_height = int(max_images / grid_width)\n",
        "fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width*2, grid_height*2))\n",
        "\n",
        "for i,(im, mask1, mask2) in enumerate(zip(images, masks[0], masks[5])):\n",
        "    ax = axs[int(i / grid_width), i % grid_width]\n",
        "    ax.imshow(im)\n",
        "    # ax.imshow(mask1.squeeze(), alpha=0.4)\n",
        "    ax.imshow(mask2, alpha=0.4)\n",
        "    ax.axis('off')\n",
        "\n",
        "print(mask1.shape)\n",
        "print(mask2.shape)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjqpdPNXTZ66"
      },
      "source": [
        "## Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.applications import VGG19\n",
        "from keras.layers import Input, Activation, UpSampling2D, concatenate, MaxPool2D\n",
        "from keras.layers import Conv2D, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.initializers import he_normal"
      ],
      "metadata": {
        "id": "XDR4MH1XF_P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/hamidriasat/UNet-3-Plus/blob/unet3p_lits/models/unet3plus_deep_supervision.py\n",
        "\n",
        "def conv_block(x, kernels, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
        "               is_bn=True, is_relu=True, n=2):\n",
        "    \"\"\" Custom function for conv2d:\n",
        "        Apply  3*3 convolutions with BN and relu.\n",
        "    \"\"\"\n",
        "    for i in range(1, n + 1):\n",
        "        x = Conv2D(filters=kernels, kernel_size=kernel_size,\n",
        "                   padding=padding, strides=strides,\n",
        "                   kernel_regularizer=l2(1e-4),\n",
        "                   kernel_initializer=he_normal(seed=5))(x)\n",
        "        if is_bn:\n",
        "            x = BatchNormalization()(x)\n",
        "        if is_relu:\n",
        "            x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def unet3plus_deepsup(input_shape, deep_supervision=False):\n",
        "    \"\"\" UNet_3Plus with Deep Supervision \"\"\"\n",
        "    # filters = [64, 128, 256, 512, 1024]\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "\n",
        "    input_layer = Input(shape=input_shape, name=\"input_layer\")  # 320*320*3\n",
        "\n",
        "    \"\"\" Encoder\"\"\"\n",
        "    skip_connections = []\n",
        "\n",
        "    model = VGG19(include_top=False, weights=\"imagenet\", input_tensor=input_layer)\n",
        "    names = [\"block1_conv2\", \"block2_conv2\", \"block3_conv4\", \"block4_conv4\"]\n",
        "    for name in names:\n",
        "        skip_connections.append(model.get_layer(name).output)\n",
        "\n",
        "    output = model.get_layer(\"block5_conv4\").output\n",
        "\n",
        "    # block 5\n",
        "    # bottleneck layer\n",
        "    e5 = conv_block(output, filters[4])  # 20*20*1024\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    cat_channels = filters[0]\n",
        "    cat_blocks = len(filters)\n",
        "    upsample_channels = cat_blocks * cat_channels\n",
        "\n",
        "    \"\"\" d4_1 \"\"\"\n",
        "    e1_d4_1 = MaxPool2D(pool_size=(8, 8))(skip_connections[0])  # 320*320*64  --> 40*40*64\n",
        "    e1_d4_1 = conv_block(e1_d4_1, cat_channels, n=1)  # 320*320*64  --> 40*40*64\n",
        "\n",
        "    e2_d4_1 = MaxPool2D(pool_size=(4, 4))(skip_connections[1])  # 160*160*128 --> 40*40*128\n",
        "    e2_d4_1 = conv_block(e2_d4_1, cat_channels, n=1)  # 160*160*128 --> 40*40*64\n",
        "\n",
        "    e3_d4_1 = MaxPool2D(pool_size=(2, 2))(skip_connections[2])  # 80*80*256  --> 40*40*256\n",
        "    e3_d4_1 = conv_block(e3_d4_1, cat_channels, n=1)  # 80*80*256  --> 40*40*64\n",
        "\n",
        "    e4_d4_1 = conv_block(skip_connections[3], cat_channels, n=1)  # 40*40*512  --> 40*40*64\n",
        "\n",
        "    e5_d4_1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(e5)  # 80*80*256  --> 40*40*256\n",
        "    e5_d4_1 = conv_block(e5_d4_1, cat_channels, n=1)  # 20*20*1024  --> 20*20*64\n",
        "\n",
        "    d4_1 = concatenate([e1_d4_1, e2_d4_1, e3_d4_1, e4_d4_1, e5_d4_1])\n",
        "    d4_1 = conv_block(d4_1, upsample_channels, n=1)  # 40*40*320  --> 40*40*320\n",
        "\n",
        "    \"\"\" d3_1 \"\"\"\n",
        "    e1_d3_1 = MaxPool2D(pool_size=(4, 4))(skip_connections[0])  # 320*320*64 --> 80*80*64\n",
        "    e1_d3_1 = conv_block(e1_d3_1, cat_channels, n=1)  # 80*80*64 --> 80*80*64\n",
        "\n",
        "    e2_d3_1 = MaxPool2D(pool_size=(2, 2))(skip_connections[1])  # 160*160*256 --> 80*80*256\n",
        "    e2_d3_1 = conv_block(e2_d3_1, cat_channels, n=1)  # 80*80*256 --> 80*80*64\n",
        "\n",
        "    e3_d3_1 = conv_block(skip_connections[2], cat_channels, n=1)  # 80*80*512 --> 80*80*64\n",
        "\n",
        "    e4_d3_1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(d4_1)  # 40*40*320 --> 80*80*320\n",
        "    e4_d3_1 = conv_block(e4_d3_1, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
        "\n",
        "    e5_d3_1 = UpSampling2D(size=(4, 4), interpolation='bilinear')(e5)  # 20*20*320 --> 80*80*320\n",
        "    e5_d3_1 = conv_block(e5_d3_1, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
        "\n",
        "    d3_1 = concatenate([e1_d3_1, e2_d3_1, e3_d3_1, e4_d3_1, e5_d3_1])\n",
        "    d3_1 = conv_block(d3_1, upsample_channels, n=1)  # 80*80*320 --> 80*80*320\n",
        "\n",
        "    \"\"\" d2_1 \"\"\"\n",
        "    e1_d2_1 = MaxPool2D(pool_size=(2, 2))(skip_connections[0])  # 320*320*64 --> 160*160*64\n",
        "    e1_d2_1 = conv_block(e1_d2_1, cat_channels, n=1)  # 160*160*64 --> 160*160*64\n",
        "\n",
        "    e2_d2_1 = conv_block(skip_connections[1], cat_channels, n=1)  # 160*160*256 --> 160*160*64\n",
        "\n",
        "    d3_d2_1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(d3_1)  # 80*80*320 --> 160*160*320\n",
        "    d3_d2_1 = conv_block(d3_d2_1, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d4_d2_1 = UpSampling2D(size=(4, 4), interpolation='bilinear')(d4_1)  # 40*40*320 --> 160*160*320\n",
        "    d4_d2_1 = conv_block(d4_d2_1, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    e5_d2_1 = UpSampling2D(size=(8, 8), interpolation='bilinear')(e5)  # 20*20*320 --> 160*160*320\n",
        "    e5_d2_1 = conv_block(e5_d2_1, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d2_1 = concatenate([e1_d2_1, e2_d2_1, d3_d2_1, d4_d2_1, e5_d2_1])\n",
        "    d2_1 = conv_block(d2_1, upsample_channels, n=1)  # 160*160*320 --> 160*160*320\n",
        "\n",
        "    \"\"\" d1_1 \"\"\"\n",
        "    e1_d1_1 = conv_block(skip_connections[0], cat_channels, n=1)  # 320*320*64 --> 320*320*64\n",
        "\n",
        "    d2_d1_1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(d2_1)  # 160*160*320 --> 320*320*320\n",
        "    d2_d1_1 = conv_block(d2_d1_1, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d3_d1_1 = UpSampling2D(size=(4, 4), interpolation='bilinear')(d3_1)  # 80*80*320 --> 320*320*320\n",
        "    d3_d1_1 = conv_block(d3_d1_1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    d4_d1_1 = UpSampling2D(size=(8, 8), interpolation='bilinear')(d4_1)  # 40*40*320 --> 320*320*320\n",
        "    d4_d1_1 = conv_block(d4_d1_1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    e5_d1_1 = UpSampling2D(size=(16, 16), interpolation='bilinear')(e5)  # 20*20*320 --> 320*320*320\n",
        "    e5_d1_1 = conv_block(e5_d1_1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    d1_1 = concatenate([e1_d1_1, d2_d1_1, d3_d1_1, d4_d1_1, e5_d1_1, ])\n",
        "    d1_1 = conv_block(d1_1, upsample_channels, n=1)  # 320*320*320 --> 320*320*320\n",
        "\n",
        "    # last layer does not have batch norm and relu\n",
        "    d1_1 = conv_block(d1_1, 1, n=1, is_bn=False, is_relu=False)\n",
        "    d1_1 = Activation(\"sigmoid\", name=\"binary_final\")(d1_1)\n",
        "\n",
        "    \"\"\" d4_2 \"\"\"\n",
        "    e1_d4_2 = MaxPool2D(pool_size=(8, 8))(skip_connections[0])  # 320*320*64  --> 40*40*64\n",
        "    e1_d4_2 = conv_block(e1_d4_2, cat_channels, n=1)  # 320*320*64  --> 40*40*64\n",
        "\n",
        "    e2_d4_2 = MaxPool2D(pool_size=(4, 4))(skip_connections[1])  # 160*160*128 --> 40*40*128\n",
        "    e2_d4_2 = conv_block(e2_d4_2, cat_channels, n=1)  # 160*160*128 --> 40*40*64\n",
        "\n",
        "    e3_d4_2 = MaxPool2D(pool_size=(2, 2))(skip_connections[2])  # 80*80*256  --> 40*40*256\n",
        "    e3_d4_2 = conv_block(e3_d4_2, cat_channels, n=1)  # 80*80*256  --> 40*40*64\n",
        "\n",
        "    e4_d4_2 = conv_block(skip_connections[3], cat_channels, n=1)  # 40*40*512  --> 40*40*64\n",
        "\n",
        "    e5_d4_2 = UpSampling2D(size=(2, 2), interpolation='bilinear')(e5)  # 80*80*256  --> 40*40*256\n",
        "    e5_d4_2 = conv_block(e5_d4_2, cat_channels, n=1)  # 20*20*1024  --> 20*20*64\n",
        "\n",
        "    d4_2 = concatenate([e1_d4_2, e2_d4_2, e3_d4_2, e4_d4_2, e5_d4_2])\n",
        "    d4_2 = conv_block(d4_2, upsample_channels, n=1)  # 40*40*320  --> 40*40*320\n",
        "\n",
        "    \"\"\" d3_2 \"\"\"\n",
        "    e1_d3_2 = MaxPool2D(pool_size=(4, 4))(skip_connections[0])  # 320*320*64 --> 80*80*64\n",
        "    e1_d3_2 = conv_block(e1_d3_2, cat_channels, n=1)  # 80*80*64 --> 80*80*64\n",
        "\n",
        "    e2_d3_2 = MaxPool2D(pool_size=(2, 2))(skip_connections[1])  # 160*160*256 --> 80*80*256\n",
        "    e2_d3_2 = conv_block(e2_d3_2, cat_channels, n=1)  # 80*80*256 --> 80*80*64\n",
        "\n",
        "    e3_d3_2 = conv_block(skip_connections[2], cat_channels, n=1)  # 80*80*512 --> 80*80*64\n",
        "\n",
        "    e4_d3_2 = UpSampling2D(size=(2, 2), interpolation='bilinear')(d4_2)  # 40*40*320 --> 80*80*320\n",
        "    e4_d3_2 = conv_block(e4_d3_2, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
        "\n",
        "    e5_d3_2 = UpSampling2D(size=(4, 4), interpolation='bilinear')(e5)  # 20*20*320 --> 80*80*320\n",
        "    e5_d3_2 = conv_block(e5_d3_2, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
        "\n",
        "    d3_2 = concatenate([e1_d3_2, e2_d3_2, e3_d3_2, e4_d3_2, e5_d3_2])\n",
        "    d3_2 = conv_block(d3_2, upsample_channels, n=1)  # 80*80*320 --> 80*80*320\n",
        "\n",
        "    \"\"\" d2_2 \"\"\"\n",
        "    e1_d2_2 = MaxPool2D(pool_size=(2, 2))(skip_connections[0])  # 320*320*64 --> 160*160*64\n",
        "    e1_d2_2 = conv_block(e1_d2_2, cat_channels, n=1)  # 160*160*64 --> 160*160*64\n",
        "\n",
        "    e2_d2_2 = conv_block(skip_connections[1], cat_channels, n=1)  # 160*160*256 --> 160*160*64\n",
        "\n",
        "    d3_d2_2 = UpSampling2D(size=(2, 2), interpolation='bilinear')(d3_2)  # 80*80*320 --> 160*160*320\n",
        "    d3_d2_2 = conv_block(d3_d2_2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d4_d2_2 = UpSampling2D(size=(4, 4), interpolation='bilinear')(d4_2)  # 40*40*320 --> 160*160*320\n",
        "    d4_d2_2 = conv_block(d4_d2_2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    e5_d2_2 = UpSampling2D(size=(8, 8), interpolation='bilinear')(e5)  # 20*20*320 --> 160*160*320\n",
        "    e5_d2_2 = conv_block(e5_d2_2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d2_2 = concatenate([e1_d2_2, e2_d2_2, d3_d2_2, d4_d2_2, e5_d2_2])\n",
        "    d2_2 = conv_block(d2_2, upsample_channels, n=1)  # 160*160*320 --> 160*160*320\n",
        "\n",
        "    \"\"\" d1_2 \"\"\"\n",
        "    e1_d1_2 = conv_block(skip_connections[0], cat_channels, n=1)  # 320*320*64 --> 320*320*64\n",
        "\n",
        "    d2_d1_2 = UpSampling2D(size=(2, 2), interpolation='bilinear')(d2_2)  # 160*160*320 --> 320*320*320\n",
        "    d2_d1_2 = conv_block(d2_d1_2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d3_d1_2 = UpSampling2D(size=(4, 4), interpolation='bilinear')(d3_2)  # 80*80*320 --> 320*320*320\n",
        "    d3_d1_2 = conv_block(d3_d1_2, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    d4_d1_2 = UpSampling2D(size=(8, 8), interpolation='bilinear')(d4_2)  # 40*40*320 --> 320*320*320\n",
        "    d4_d1_2 = conv_block(d4_d1_2, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    e5_d1_2 = UpSampling2D(size=(16, 16), interpolation='bilinear')(e5)  # 20*20*320 --> 320*320*320\n",
        "    e5_d1_2 = conv_block(e5_d1_2, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    d1_2 = concatenate([e1_d1_2, d2_d1_2, d3_d1_2, d4_d1_2, e5_d1_2, ])\n",
        "    d1_2 = conv_block(d1_2, upsample_channels, n=1)  # 320*320*320 --> 320*320*320\n",
        "\n",
        "    # last layer does not have batch norm and relu\n",
        "    d1_2 = conv_block(d1_2, 3, n=1, is_bn=False, is_relu=False)\n",
        "    d1_2 = Activation(\"softmax\", name=\"multi_final\")(d1_2)\n",
        "\n",
        "    \"\"\" Deep Supervision Part\"\"\"\n",
        "    if deep_supervision:\n",
        "        # Binary super-vision\n",
        "        d2_1 = conv_block(d2_1, 1, n=1, is_bn=False, is_relu=False)\n",
        "        d3_1 = conv_block(d3_1, 1, n=1, is_bn=False, is_relu=False)\n",
        "        d4_1 = conv_block(d4_1, 1, n=1, is_bn=False, is_relu=False)\n",
        "        e5_1 = conv_block(e5, 1, n=1, is_bn=False, is_relu=False)\n",
        "\n",
        "        # d1_1 = no need for up sampling\n",
        "        d2_1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(d2_1)\n",
        "        d3_1 = UpSampling2D(size=(4, 4), interpolation='bilinear')(d3_1)\n",
        "        d4_1 = UpSampling2D(size=(8, 8), interpolation='bilinear')(d4_1)\n",
        "        e5_1 = UpSampling2D(size=(16, 16), interpolation='bilinear')(e5_1)\n",
        "\n",
        "        d2_1 = Activation(\"sigmoid\", name=\"binary_sup1\")(d2_1)\n",
        "        d3_1 = Activation(\"sigmoid\", name=\"binary_sup2\")(d3_1)\n",
        "        d4_1 = Activation(\"sigmoid\", name=\"binary_sup3\")(d4_1)\n",
        "        e5_1 = Activation(\"sigmoid\", name=\"binary_sup4\")(e5_1)\n",
        "\n",
        "        # Multi-class super-vision\n",
        "        d2_2 = conv_block(d2_2, 3, n=1, is_bn=False, is_relu=False)\n",
        "        d3_2 = conv_block(d3_2, 3, n=1, is_bn=False, is_relu=False)\n",
        "        d4_2 = conv_block(d4_2, 3, n=1, is_bn=False, is_relu=False)\n",
        "        e5_2 = conv_block(e5, 3, n=1, is_bn=False, is_relu=False)\n",
        "\n",
        "        # d1_2 = no need for up sampling\n",
        "        d2_2 = UpSampling2D(size=(2, 2), interpolation='bilinear')(d2_2)\n",
        "        d3_2 = UpSampling2D(size=(4, 4), interpolation='bilinear')(d3_2)\n",
        "        d4_2 = UpSampling2D(size=(8, 8), interpolation='bilinear')(d4_2)\n",
        "        e5_2 = UpSampling2D(size=(16, 16), interpolation='bilinear')(e5_2)\n",
        "\n",
        "        d2_2 = Activation(\"softmax\", name=\"multi_sup1\")(d2_2)\n",
        "        d3_2 = Activation(\"softmax\", name=\"multi_sup2\")(d3_2)\n",
        "        d4_2 = Activation(\"softmax\", name=\"multi_sup3\")(d4_2)\n",
        "        e5_2 = Activation(\"softmax\", name=\"multi_sup4\")(e5_2)\n",
        "\n",
        "    if deep_supervision:\n",
        "        return Model(inputs=input_layer, outputs=[d1_1, d2_1, d3_1, d4_1, e5_1,\n",
        "                                                  d1_2, d2_2, d3_2, d4_2, e5_2], name='UNet3Plus_DeepSup')\n",
        "    else:\n",
        "        return Model(inputs=input_layer, outputs=[d1_1, d1_2], name='UNet3Plus_DeepSup')"
      ],
      "metadata": {
        "id": "OEU-uiyAGIHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = [256, 256, 3]\n",
        "\n",
        "model = unet3plus_deepsup(INPUT_SHAPE, deep_supervision=True)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-qvwSpcLHmoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jC-eAphWUub"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpGYX_INWXgp"
      },
      "outputs": [],
      "source": [
        "plot_model(model, show_shapes=True, dpi=330, to_file=\"U-Net3+_DD.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ8oAgALaj8-"
      },
      "source": [
        "### Defining loss function for binary & multi segmentation tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as9BTX7-Zpg0"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzBhjLo2ayHx"
      },
      "outputs": [],
      "source": [
        "# https://github.com/yingkaisha/keras-unet-collection\n",
        "!pip install keras_unet_collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efXpJJ4QfjXK"
      },
      "outputs": [],
      "source": [
        "from keras_unet_collection import losses\n",
        "\n",
        "def binary_loss(y_true, y_pred):\n",
        "\n",
        "    loss_focal = losses.focal_tversky(y_true, y_pred, alpha=0.5, gamma=4/3)\n",
        "    loss_iou = losses.iou_seg(y_true, y_pred)\n",
        "    \n",
        "    # (x) \n",
        "    # loss_ssim = losses.ms_ssim(y_true, y_pred, max_val=1.0, filter_size=4)\n",
        "    \n",
        "    return loss_focal+loss_iou #+loss_ssim\n",
        "\n",
        "def multi_loss(y_true, y_pred):\n",
        "\n",
        "    loss_focal = losses.focal_tversky(y_true, y_pred, alpha=0.7, gamma=4/3)\n",
        "    loss_iou = losses.iou_seg(y_true, y_pred)\n",
        "    \n",
        "    # (x) \n",
        "    # loss_ssim = losses.ms_ssim(y_true, y_pred, max_val=1.0, filter_size=4)\n",
        "    \n",
        "    return loss_focal+loss_iou #+loss_ssim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUN_1pCkaDZW"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ET3WNbwb3U-"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHRIkAr_bWjn"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(1e-4),\n",
        "              loss={\n",
        "                    \"binary_final\":binary_loss,\n",
        "                    \"binary_sup1\":binary_loss,\n",
        "                    \"binary_sup2\":binary_loss,\n",
        "                    \"binary_sup3\":binary_loss, \n",
        "                    \"binary_sup4\":binary_loss,\n",
        "                    \"multi_final\":multi_loss,\n",
        "                    \"multi_sup1\":multi_loss,\n",
        "                    \"multi_sup2\":multi_loss,\n",
        "                    \"multi_sup3\":multi_loss, \n",
        "                    \"multi_sup4\":multi_loss\n",
        "                    },\n",
        "              loss_weights=[1.0, 0.25, 0.25, 0.25, 0.25, 1.0, 0.25, 0.25, 0.25, 0.25],\n",
        "              metrics={\n",
        "                       \"binary_final\":dice_coef,\n",
        "                       \"binary_sup1\":dice_coef,\n",
        "                       \"binary_sup2\":dice_coef,\n",
        "                       \"binary_sup3\":dice_coef, \n",
        "                       \"binary_sup4\":dice_coef,\n",
        "                       \"multi_final\":dice_coef,\n",
        "                       \"multi_sup1\":dice_coef,\n",
        "                       \"multi_sup2\":dice_coef,\n",
        "                       \"multi_sup3\":dice_coef, \n",
        "                       \"multi_sup4\":dice_coef\n",
        "                       })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NY7qhfHdjT9"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwcWk3exb1Dt"
      },
      "source": [
        "### Defining some useful callbacks "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADk25mhZcCsi"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, Callback, LearningRateScheduler\n",
        "# from tensorflow.keras.optimizers.schedules import CosineDecay\n",
        "import datetime\n",
        "\n",
        "from skimage import filters\n",
        "from scipy.ndimage import measurements\n",
        "from skimage.segmentation import watershed, mark_boundaries\n",
        "\n",
        "# Visualize training \n",
        "class loss_history(Callback):\n",
        "\n",
        "    def __init__(self, x=4):\n",
        "        self.x = x\n",
        "    \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        fig, ax = plt.subplots(1, 5, figsize=(18, 12))\n",
        "        [axi.set_axis_off() for axi in ax.ravel()]\n",
        "\n",
        "        ax[0].imshow(train_images[self.x])\n",
        "        ax[0].set_title(\"Tissue Image\")\n",
        "\n",
        "        ax[1].imshow(train_masks[self.x], cmap=\"gray\")\n",
        "        ax[1].set_title(\"Ground Truth\")\n",
        "\n",
        "        model_sample_input = train_images[self.x].astype(\"float32\") / 255.\n",
        "        pred = self.model.predict(np.expand_dims(model_sample_input, axis=0), verbose=0)\n",
        "        preds_train1 = pred[0]\n",
        "        preds_train2 = pred[5]\n",
        "        preds1 =  np.squeeze(preds_train1[0]) >= 0.5\n",
        "        ax[2].imshow(preds1, cmap=\"gray\")\n",
        "        ax[2].set_title(\"Nuclei prediction\")\n",
        "        preds2 = preds_train2[0][:, :, 2] - preds_train2[0][:, :, 1] >= 0.5\n",
        "        ax[3].imshow(preds2, cmap=\"gray\")\n",
        "        ax[3].set_title(\"Nuclei marker prediction\")\n",
        "        \n",
        "        grad = filters.scharr(preds1)\n",
        "        marker = preds1 * preds2\n",
        "        marker = measurements.label(marker)[0]\n",
        "        proced_pred = watershed(grad, marker, mask=preds1)\n",
        "        ax[4].imshow(mark_boundaries(train_images[self.x], proced_pred, color=(0, 0, 1)))\n",
        "        ax[4].set_title(\"Result\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# lr_scheduler = CosineDecay(\n",
        "#     1e-4, 50, alpha=0.0, name=None\n",
        "# )\n",
        "\n",
        "create_path(\"logs/Unet3+\")\n",
        "csv_log = CSVLogger('logs/Unet3+/Unet3+_fold1_log00.csv', separator=',')\n",
        "model_name = f\"Unet3+_fold1_v00_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "create_path(\"models/Unet3+\")\n",
        "path_to_save_model = \"models/Unet3+/\" + model_name + \".h5\"\n",
        "checkpointer = ModelCheckpoint(path_to_save_model, verbose=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-7, verbose=1)\n",
        "# reduce_lr = LearningRateScheduler(schedule=lr_scheduler)\n",
        "early_stop   = EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=False)\n",
        "\n",
        "print(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWlQhnxEdBDc"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "             loss_history(), \n",
        "             checkpointer, \n",
        "             reduce_lr, \n",
        "            #  csv_log, \n",
        "             early_stop\n",
        "             ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7X3dJTMdn5t"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "epochs = 200\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(train_images, train_masks, train_masks_cat, augmentations=AUGMENTATIONS_TRAIN, batch_size=batch_size)\n",
        "validation_generator = DataGenerator(val_images, val_masks, val_masks_cat, augmentations=AUGMENTATIONS_VAL, batch_size=batch_size)\n",
        "\n",
        "history = model.fit(training_generator,\n",
        "                    validation_data=validation_generator,                        \n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_OYcrtwmjcE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}