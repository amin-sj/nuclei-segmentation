{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1qaMdyfGR4fqBIfPdHaSI4r9DXcXUDWxL","authorship_tag":"ABX9TyMURj1ed0CB6wIIxg33Gk2J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Stain normalization"],"metadata":{"id":"888FblbbygBT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5f7Nk2jvbTK","executionInfo":{"status":"ok","timestamp":1671694608746,"user_tz":-210,"elapsed":79866,"user":{"displayName":"Seyed amin Seyed jafari","userId":"14892894530811864169"}},"outputId":"9ed62365-015f-4eeb-dbc2-9a7bdc17d6e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-22 07:35:23--  https://raw.githubusercontent.com/wanghao14/Stain_Normalization/master/stain_utils.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4255 (4.2K) [text/plain]\n","Saving to: ‘stain_utils.py’\n","\n","\rstain_utils.py        0%[                    ]       0  --.-KB/s               \rstain_utils.py      100%[===================>]   4.16K  --.-KB/s    in 0s      \n","\n","2022-12-22 07:35:23 (34.7 MB/s) - ‘stain_utils.py’ saved [4255/4255]\n","\n","--2022-12-22 07:35:23--  https://raw.githubusercontent.com/wanghao14/Stain_Normalization/master/stainNorm_Macenko.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2663 (2.6K) [text/plain]\n","Saving to: ‘stainNorm_Macenko.py’\n","\n","stainNorm_Macenko.p 100%[===================>]   2.60K  --.-KB/s    in 0s      \n","\n","2022-12-22 07:35:23 (34.3 MB/s) - ‘stainNorm_Macenko.py’ saved [2663/2663]\n","\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spams\n","  Downloading spams-2.6.5.4.tar.gz (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 4.7 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Pillow>=6.0 in /usr/local/lib/python3.8/dist-packages (from spams) (7.1.2)\n","Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.8/dist-packages (from spams) (1.21.6)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from spams) (1.7.3)\n","Building wheels for collected packages: spams\n","  Building wheel for spams (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for spams: filename=spams-2.6.5.4-cp38-cp38-linux_x86_64.whl size=3241025 sha256=b3649c8778a7ef551047bcd5a06c5583867f8c00e91ac6dd3d1f7457d8981413\n","  Stored in directory: /root/.cache/pip/wheels/38/d6/cd/b79299cdb26aa57760dbbeb096bc8b71b10c69f4bb95dbd16c\n","Successfully built spams\n","Installing collected packages: spams\n","Successfully installed spams-2.6.5.4\n"]}],"source":["# https://github.com/wanghao14/Stain_Normalization\n","!wget https://raw.githubusercontent.com/wanghao14/Stain_Normalization/master/stain_utils.py\n","!wget https://raw.githubusercontent.com/wanghao14/Stain_Normalization/master/stainNorm_Macenko.py\n","!pip install spams"]},{"cell_type":"code","source":["# !pwd"],"metadata":{"id":"nBftYz0RxbQ-","executionInfo":{"status":"ok","timestamp":1671698245398,"user_tz":-210,"elapsed":4,"user":{"displayName":"Seyed amin Seyed jafari","userId":"14892894530811864169"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# %cd drive/MyDrive/nuclei_segmentation"],"metadata":{"id":"AgEAlL9rxctw","executionInfo":{"status":"ok","timestamp":1671698248295,"user_tz":-210,"elapsed":3,"user":{"displayName":"Seyed amin Seyed jafari","userId":"14892894530811864169"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# !ls"],"metadata":{"id":"NZTJqKfAxp1b","executionInfo":{"status":"ok","timestamp":1671698251818,"user_tz":-210,"elapsed":5,"user":{"displayName":"Seyed amin Seyed jafari","userId":"14892894530811864169"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","import glob\n","import shutil\n","import numpy as np\n","from tqdm import tqdm\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import stain_utils as utils\n","import stainNorm_Macenko"],"metadata":{"id":"sXB3Dw3NwlFe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def  macenko_normalize(img_dir: str, ref_img_dir:str):\n","    # read image\n","    img = utils.read_image(img_dir)\n","    n = stainNorm_Macenko.Normalizer()\n","\n","    # fit macenko normallizer on reference image\n","    n.fit(np.array(Image.open(ref_img_dir))) \n","\n","    # stain normalize H&E image\n","    normalized_img = n.transform(img)\n","\n","    return normalized_img"],"metadata":{"id":"GFuvOpD-wtRI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_path(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)"],"metadata":{"id":"95_Z3ibvw6xj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dir = \"dataset/monuseg/original/train/tissue_images\"\n","test_dir = \"dataset/monuseg/original/test/tissue_images\""],"metadata":{"id":"LT-fWMTOxaG-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_stain_normalized_images_path = \"dataset/monuseg/stain_normalized/train/tissue_images\"\n","create_path(train_stain_normalized_images_path)\n","\n","test_stain_normalized_images_path = \"dataset/monuseg/stain_normalized/test/tissue_images\"\n","create_path(test_stain_normalized_images_path)\n","\n","# reference image path \n","ref_img_dir = \"dataset/monuseg/original/train/tissue_images/TCGA-AR-A1AS-01Z-00-DX1.tif\""],"metadata":{"id":"dfyiBrOrx7sP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for image_path in tqdm(glob.glob(os.path.join(train_dir, \"*\")), total=len(os.listdir(train_dir))):\n","    name = os.path.basename(image_path)\n","    normI= macenko_normalize(image_path, ref_img_dir)\n","    normI = Image.fromarray(normI.astype(np.uint8))\n","    normI.save(os.path.join(train_stain_normalized_images_path, name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxE21xs6yYc5","executionInfo":{"status":"ok","timestamp":1671695404261,"user_tz":-210,"elapsed":113881,"user":{"displayName":"Seyed amin Seyed jafari","userId":"14892894530811864169"}},"outputId":"729b1ad2-b3b5-4f57-9959-272e18ee1b9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [01:53<00:00,  3.79s/it]\n"]}]},{"cell_type":"code","source":["for image_path in tqdm(glob.glob(os.path.join(test_dir, \"*\")), total=len(os.listdir(test_dir))):\n","    name = os.path.basename(image_path)\n","    normI= macenko_normalize(image_path, ref_img_dir)\n","    normI = Image.fromarray(normI.astype(np.uint8))\n","    normI.save(os.path.join(test_stain_normalized_images_path, name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yLPRFzJ7zf1T","executionInfo":{"status":"ok","timestamp":1671695510181,"user_tz":-210,"elapsed":50111,"user":{"displayName":"Seyed amin Seyed jafari","userId":"14892894530811864169"}},"outputId":"1411a888-ff30-4b94-cac4-254aac88a174"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 14/14 [00:49<00:00,  3.54s/it]\n"]}]},{"cell_type":"markdown","source":["## Modifying GT"],"metadata":{"id":"WhZaVsyk0YU7"}},{"cell_type":"code","source":["from xml.dom import minidom\n","from skimage.draw import polygon, polygon_perimeter"],"metadata":{"id":"Vk98hF9H0a8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://github.com/rshwndsz/hover-net\n","# generate binary masks\n","def generate_labelled_array(xml_file, shape, binary=True):\n","    \"\"\"\n","    Given the image shape and path to annotations(xml file),\n","    generate a bit mask with the region inside a contour being white\n","    shape: The image shape on which bit mask will be made\n","    xml_file: path relative to the current working directory\n","    where the xml file is present\n","    Returns: A image of given shape with region inside contour being white..\n","    \"\"\"\n","    # DOM object created by minidom\n","    xDoc = minidom.parse(xml_file)\n","\n","    # list of all region tags\n","    regions = xDoc.getElementsByTagName(\"Region\")\n","\n","    # List which will store the vertices for each region\n","    xy = []\n","    for region in regions:\n","        # Loading all the vertices in the region\n","        vertices = region.getElementsByTagName(\"Vertex\")\n","        # Vertices of a region will be stored in an array\n","        vw = np.zeros((len(vertices), 2))\n","\n","        for index, vertex in enumerate(vertices):\n","            # Storing the values of x and y coordinate\n","            vw[index][0] = float(vertex.getAttribute(\"X\"))\n","            vw[index][1] = float(vertex.getAttribute(\"Y\"))\n","\n","        # Append the vertices of a region\n","        xy.append(np.int32(vw))\n","\n","    # Creating a completely black image\n","    mask = np.zeros(shape, np.float32)\n","    # generate the bit mask\n","    for i, contour in enumerate(xy):\n","        r, c = polygon(np.array(xy[i])[:, 1]-1, np.array(xy[i])[:, 0]-1, shape=shape)\n","        if binary:\n","            mask[r, c] = 1\n","        else:\n","            mask[r, c] = i\n","    return mask\n","\n","# https://github.com/bnsreenu/python_for_microscopists/blob/master/tips_tricks_31_generating_borders_around_objects.py\n","# a function to generate border\n","def generate_boarder(_mask, boarder_size=5, n_erosions=1):\n","    # Define a kernel for erosion\n","    erosion_kernel = np.ones((3, 3), dtype=np.uint8)\n","    eroded_mask = cv2.erode(_mask, erosion_kernel, iterations=n_erosions)\n","\n","    # Define kernel size for dilation\n","    kernel_size = 2 * boarder_size + 1\n","    dilation_kernel = np.ones((kernel_size, kernel_size), dtype=np.uint8)\n","    dilated_mask = cv2.dilate(eroded_mask, dilation_kernel, iterations=1)\n","\n","    dilated_127 = np.where(dilated_mask == 255, 127, 0)\n","\n","    mask_with_boarders = np.where(eroded_mask > 0, 255, dilated_127)\n","\n","    return mask_with_boarders\n","\n","def generate_masks_with_boarders(xml_file, shape):\n","    \"\"\"\n","    Given the image shape and path to annotations(xml file),\n","    generate a bit mask with the region inside a contour being white\n","    this function will remove overlapping areas and save the genrated mask\n","    shape: The image shape on which bit mask will be made\n","    xml_file: path relative to the current working directory\n","    where the xml file is present\n","    save_dir: directory to save the masks\n","    \"\"\"\n","    xDoc = minidom.parse(xml_file)\n","\n","    # list of all region tags\n","    regions = xDoc.getElementsByTagName(\"Region\")\n","\n","    # List which will store the vertices for each region\n","    xy = []\n","    for region in regions:\n","        # Loading all the vertices in the region\n","        vertices = region.getElementsByTagName(\"Vertex\")\n","        # Vertices of a region will be stored in an array\n","        vw = np.zeros((len(vertices), 2))\n","\n","        for index, vertex in enumerate(vertices):\n","            # Storing the values of x and y coordinate\n","            vw[index][0] = float(vertex.getAttribute(\"X\"))\n","            vw[index][1] = float(vertex.getAttribute(\"Y\"))\n","\n","        # Append the vertices of a region\n","        xy.append(np.int32(vw))\n","\n","    # Creating a completely black image\n","    mask = np.zeros(shape, np.float32)\n","    # generate the bit mask\n","    for i, contour in enumerate(xy):\n","        try:\n","            r1, c1 = polygon(np.array(xy[i])[:, 1], np.array(xy[i])[:, 0], shape=shape)\n","            mask[r1, c1] = 1\n","\n","            r2, c2 = polygon_perimeter(np.array(xy[i])[:, 1], np.array(xy[i])[:, 0], shape=shape)\n","            mask[r2, c2] = 0\n","        except:\n","            continue\n","\n","    # remove overlapping areas\n","    mask[mask == 1] = 255\n","    mask = generate_boarder(mask)\n","\n","    return mask"],"metadata":{"id":"CKdSWa5m0jbc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_xml_dir = \"dataset/monuseg/original/train/annotations\"\n","test_xml_dir = \"dataset/monuseg/original/test/annotations\"\n","shape = (1000, 1000)"],"metadata":{"id":"rMwTtSY55n6E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_instance_mask_path = \"dataset/monuseg/stain_normalized/train/instance_masks\"\n","create_path(train_instance_mask_path)\n","train_binary_mask_path = \"dataset/monuseg/stain_normalized/train/binary_masks\"\n","create_path(train_binary_mask_path)\n","train_modified_mask_path = \"dataset/monuseg/stain_normalized/train/modified_masks\"\n","create_path(train_modified_mask_path)\n","\n","test_instance_mask_path = \"dataset/monuseg/stain_normalized/test/instance_masks\"\n","create_path(test_instance_mask_path)\n","test_binary_mask_path = \"dataset/monuseg/stain_normalized/test/binary_masks\"\n","create_path(test_binary_mask_path)\n","test_modified_mask_path = \"dataset/monuseg/stain_normalized/test/modified_masks\"\n","create_path(test_modified_mask_path)"],"metadata":{"id":"fp4BbltA4edz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for xml_path in tqdm(glob.glob(os.path.join(train_xml_dir, \"*\")), total=len(os.listdir(train_xml_dir))):\n","    name = os.path.basename(xml_path)\n","\n","    binary_mask = generate_labelled_array(xml_path, shape, binary=True)\n","    cv2.imwrite(os.path.join(train_binary_mask_path, name.replace(\"xml\", \"png\")), binary_mask*255)\n","\n","    instance_mask = generate_labelled_array(xml_path, shape, binary=False)\n","    np.save(os.path.join(train_instance_mask_path, name.replace(\"xml\", \"npy\")), instance_mask)\n","\n","    modified_mask = generate_masks_with_boarders(xml_path, shape)\n","    cv2.imwrite(os.path.join(train_modified_mask_path, name.replace(\"xml\", \"png\")), modified_mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YY-skT4E5_r5","executionInfo":{"status":"ok","timestamp":1671697549377,"user_tz":-210,"elapsed":435733,"user":{"displayName":"Seyed amin Seyed jafari","userId":"14892894530811864169"}},"outputId":"7ed8ba7e-a95a-474d-e6da-33c9eaa5d3d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [07:15<00:00, 14.51s/it]\n"]}]},{"cell_type":"code","source":["for xml_path in tqdm(glob.glob(os.path.join(test_xml_dir, \"*\")), total=len(os.listdir(test_xml_dir))):\n","    name = os.path.basename(xml_path)\n","\n","    binary_mask = generate_labelled_array(xml_path, shape, binary=True)\n","    cv2.imwrite(os.path.join(test_binary_mask_path, name.replace(\"xml\", \"png\")), binary_mask*255)\n","\n","    instance_mask = generate_labelled_array(xml_path, shape, binary=False)\n","    np.save(os.path.join(test_instance_mask_path, name.replace(\"xml\", \"npy\")), instance_mask)\n","\n","    modified_mask = generate_masks_with_boarders(xml_path, shape)\n","    cv2.imwrite(os.path.join(test_modified_mask_path, name.replace(\"xml\", \"png\")), modified_mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_m9SCey6VOM","executionInfo":{"status":"ok","timestamp":1671697626630,"user_tz":-210,"elapsed":72838,"user":{"displayName":"Seyed amin Seyed jafari","userId":"14892894530811864169"}},"outputId":"b8b80154-dad5-48ed-cc14-41b48e272358"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 14/14 [01:12<00:00,  5.17s/it]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"og1PYIch6lg6"},"execution_count":null,"outputs":[]}]}