{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxewgf2v8VAC"
      },
      "outputs": [],
      "source": [
        "# https://github.com/qubvel/segmentation_models\n",
        "!pip install segmentation-models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models as sm\n",
        "sm.set_framework(\"tf.keras\")\n",
        "sm.framework()"
      ],
      "metadata": {
        "id": "ZErsTHFd8pmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "uOl_bQvN8xvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "metadata": {
        "id": "6c7LBnqI8zwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "aSW7wK3r81q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LUkTZxlq82sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/nuclei_segmentation"
      ],
      "metadata": {
        "id": "WExVCpI-894O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/dovahcrow/patchify.py\n",
        "!pip install patchify"
      ],
      "metadata": {
        "id": "EQeoJpEB8_uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "HwGl2I5m9B48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_path(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ],
      "metadata": {
        "id": "GBAHqpio9F28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"dataset/monuseg/stain_normalized/train\"\n",
        "val_dir = \"dataset/monuseg/stain_normalized/validation\""
      ],
      "metadata": {
        "id": "cA2BhJOg9H6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_validation_set(val_dir, train_dir, val_size=6, seed=42, fold=None):\n",
        "\n",
        "    create_path(val_dir)\n",
        "    create_path(os.path.join(val_dir, \"tissue_images\"))\n",
        "    create_path(os.path.join(val_dir, \"binary_masks\"))\n",
        "    create_path(os.path.join(val_dir, \"instance_masks\"))\n",
        "    create_path(os.path.join(val_dir, \"modified_masks\"))\n",
        "    \n",
        "    for j in sorted(glob.glob(os.path.join(val_dir, \"tissue_images\", \"*\"))):\n",
        "        try:\n",
        "            shutil.move(j, os.path.join(train_dir, \"tissue_images\"))\n",
        "            shutil.move(j.replace(\"tissue_images\", \"binary_masks\").replace(\"tif\", \"png\"), \n",
        "                        os.path.join(train_dir, \"binary_masks\"))\n",
        "            shutil.move(j.replace(\"tissue_images\", \"instance_masks\").replace(\"tif\", \"npy\"), \n",
        "                        os.path.join(train_dir, \"instance_masks\"))\n",
        "            shutil.move(j.replace(\"tissue_images\", \"modified_masks\").replace(\"tif\", \"png\"), \n",
        "                        os.path.join(train_dir, \"modified_masks\"))\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    images_lst = sorted(glob.glob(os.path.join(train_dir, \"tissue_images\", \"*\")))\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(images_lst)\n",
        "    if fold is None:\n",
        "        random.seed(seed)\n",
        "        val_lst = random.sample(images_lst, val_size)\n",
        "    else:\n",
        "        val_lst = images_lst[(fold*val_size)-val_size: fold*val_size]\n",
        "        \n",
        "\n",
        "    for i in val_lst:\n",
        "        shutil.move(i, os.path.join(val_dir, \"tissue_images\"))\n",
        "        shutil.move(i.replace(\"tissue_images\", \"binary_masks\").replace(\"tif\", \"png\"), \n",
        "                    os.path.join(val_dir, \"binary_masks\"))\n",
        "        shutil.move(i.replace(\"tissue_images\", \"instance_masks\").replace(\"tif\", \"npy\"), \n",
        "                    os.path.join(val_dir, \"instance_masks\"))\n",
        "        shutil.move(i.replace(\"tissue_images\", \"modified_masks\").replace(\"tif\", \"png\"), \n",
        "                    os.path.join(val_dir, \"modified_masks\"))\n",
        "        \n",
        "    print(f\"Validation list: {[os.path.basename(i) for i in val_lst]}\")"
      ],
      "metadata": {
        "id": "akJsRu0E9Jt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_validation_set(val_dir, train_dir, val_size=6, fold=1)"
      ],
      "metadata": {
        "id": "224XJYmq9LhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(os.path.join(val_dir, \"modified_masks\")))"
      ],
      "metadata": {
        "id": "lOWEo_2T9Nx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from patchify import patchify, unpatchify"
      ],
      "metadata": {
        "id": "MzTImpjq9P9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"dataset/monuseg/stain_normalized/train/tissue_images\"\n",
        "train_maskdir = \"dataset/monuseg/stain_normalized/train/binary_masks\"\n",
        "\n",
        "val_dir   = \"dataset/monuseg/stain_normalized/validation/tissue_images\"\n",
        "val_maskdir = \"dataset/monuseg/stain_normalized/validation/binary_masks\""
      ],
      "metadata": {
        "id": "TnislEhx9SYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = 1024\n",
        "H = 1024\n",
        "\n",
        "patch_size = (256, 256, 3)\n",
        "all_img_patches = []\n",
        "for x in tqdm(sorted(glob.glob(os.path.join(train_dir, \"*\"))), total=len(os.listdir(train_dir))):\n",
        "    single_img = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "    single_img = cv2.cvtColor(single_img, cv2.COLOR_BGR2RGB)\n",
        "    single_img = cv2.resize(single_img, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "    # patchify\n",
        "    single_img_patches = patchify(single_img, patch_size=patch_size, step=128)\n",
        "    # squeeze\n",
        "    single_img_patches = np.squeeze(single_img_patches)\n",
        "\n",
        "    for i in range(single_img_patches.shape[0]):\n",
        "        for j in range(single_img_patches.shape[1]):\n",
        "            all_img_patches.append(single_img_patches[i, j])\n",
        "    \n",
        "train_images = np.array(all_img_patches)"
      ],
      "metadata": {
        "id": "Imb933h19xKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "id": "EM6SvTYu90Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_img_patches = []\n",
        "for x in tqdm(sorted(glob.glob(os.path.join(val_dir, \"*\"))), total=len(os.listdir(val_dir))):\n",
        "    single_img = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "    single_img = cv2.cvtColor(single_img, cv2.COLOR_BGR2RGB)\n",
        "    single_img = cv2.resize(single_img, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "    # patchify\n",
        "    single_img_patches = patchify(single_img, patch_size=patch_size, step=128)\n",
        "    # squeeze\n",
        "    single_img_patches = np.squeeze(single_img_patches)\n",
        "\n",
        "    for i in range(single_img_patches.shape[0]):\n",
        "        for j in range(single_img_patches.shape[1]):\n",
        "            all_img_patches.append(single_img_patches[i, j])\n",
        "\n",
        "val_images = np.array(all_img_patches)"
      ],
      "metadata": {
        "id": "rP0Se1THA6mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images.shape"
      ],
      "metadata": {
        "id": "Ot7F4KWUA9GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_mask_patches = []\n",
        "for x in tqdm(sorted(glob.glob(os.path.join(train_maskdir, \"*\"))), total=len(os.listdir(train_maskdir))):\n",
        "    single_mask = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
        "    single_mask = cv2.resize(single_mask, (W, H), interpolation=cv2.INTER_NEAREST)\n",
        "    # patchify\n",
        "    single_mask_patches = patchify(single_mask, patch_size=(256, 256), step=128)\n",
        "    # squeeze\n",
        "    single_mask_patches = np.squeeze(single_mask_patches)\n",
        "\n",
        "    for i in range(single_mask_patches.shape[0]):\n",
        "        for j in range(single_mask_patches.shape[1]):\n",
        "            all_mask_patches.append(single_mask_patches[i, j])\n",
        "\n",
        "train_masks = np.array(all_mask_patches)"
      ],
      "metadata": {
        "id": "ktTaKT37A-tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks.shape"
      ],
      "metadata": {
        "id": "e4ohYE2eA_nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_mask_patches = []\n",
        "for x in tqdm(sorted(glob.glob(os.path.join(val_maskdir, \"*\"))), total=len(os.listdir(val_maskdir))):\n",
        "    single_mask = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
        "    single_mask = cv2.resize(single_mask, (W, H), interpolation=cv2.INTER_NEAREST)\n",
        "    # patchify\n",
        "    single_mask_patches = patchify(single_mask, patch_size=(256, 256), step=128)\n",
        "    # squeeze\n",
        "    single_mask_patches = np.squeeze(single_mask_patches)\n",
        "\n",
        "    for i in range(single_mask_patches.shape[0]):\n",
        "        for j in range(single_mask_patches.shape[1]):\n",
        "            all_mask_patches.append(single_mask_patches[i, j])\n",
        "\n",
        "val_masks = np.array(all_mask_patches)"
      ],
      "metadata": {
        "id": "b4vyJugPBDR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_masks.shape"
      ],
      "metadata": {
        "id": "v4TOIJKIBGC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "rnd = np.random.randint(len(train_images))\n",
        "# rnd = 222\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "[axi.set_axis_off() for axi in ax.ravel()]\n",
        "\n",
        "ax[0].imshow(train_images[rnd])\n",
        "ax[0].set_title(\"Tissue Image\")\n",
        "\n",
        "ax[1].imshow(train_masks[rnd])\n",
        "ax[1].set_title(\"Mask\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VqWNxb1HBJK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from keras.utils import Sequence"
      ],
      "metadata": {
        "id": "5uQVHyihBOL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, images, masks, augmentations=None, batch_size=8, img_size=256, n_channels=3, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "\n",
        "        self.img_size = img_size\n",
        "        \n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augmentations\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indices of the batch\n",
        "        indices = self.indices[index * self.batch_size: min((index + 1) * self.batch_size, len(self.images))]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.data_generation(indices)\n",
        "\n",
        "        if self.augment is None:\n",
        "            return np.array(X), np.array(y)\n",
        "        else:            \n",
        "            im, mask = [], []\n",
        "            for x, y in zip(X, y):\n",
        "                augmented = self.augment(image=x, mask=y)\n",
        "                im.append(augmented['image'])\n",
        "                mask.append(augmented['mask'])\n",
        "\n",
        "            return np.array(im), np.array(mask)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indices after each epoch'\n",
        "        self.indices = np.arange(len(self.images))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def data_generation(self, indices):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((len(indices), self.img_size, self.img_size, self.n_channels))\n",
        "        y = np.empty((len(indices), self.img_size, self.img_size, 1))\n",
        "        # Generate data\n",
        "        for n, i in enumerate(indices):\n",
        "            X[n] = self.images[i]\n",
        "            y[n] = (self.masks[i]/255.)[..., np.newaxis]\n",
        "\n",
        "        return np.uint8(X), np.float32(y)"
      ],
      "metadata": {
        "id": "A3iFvJBpBT22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUGMENTATIONS_TRAIN = A.Compose([\n",
        "    A.Rotate(limit=360, p=0.5),\n",
        "    A.OneOf([\n",
        "        A.HorizontalFlip(),\n",
        "        A.VerticalFlip(),\n",
        "        ], p=0.5),\n",
        "    A.OneOf([\n",
        "        A.RandomBrightnessContrast(),\n",
        "        A.RandomGamma(),\n",
        "        A.GaussNoise()\n",
        "         ], p=0.3),\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
        "        # A.ElasticTransform(alpha=3, sigma=150, alpha_affine=150),\n",
        "        # A.ElasticTransform(),\n",
        "        A.Affine(translate_percent=0.2, shear=30, mode=cv2.BORDER_CONSTANT),\n",
        "        A.GridDistortion(),\n",
        "        A.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n",
        "        ], p=0.3),\n",
        "    A.OneOf([\n",
        "        A.RGBShift(r_shift_limit=40, g_shift_limit=40,  b_shift_limit=40),\n",
        "        A.ColorJitter(hue=0.1),\n",
        "        A.Blur(blur_limit=3)\n",
        "        ], p=0.3),\n",
        "    A.ToFloat(max_value=255)\n",
        "], p=1)\n",
        "\n",
        "AUGMENTATIONS_VAL = A.Compose([\n",
        "    A.ToFloat(max_value=255)\n",
        "], p=1)"
      ],
      "metadata": {
        "id": "RG-571L_Bxkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single tissue image with 256*256 tiles (50% overlap between tiles) without augmentation\n",
        "a = DataGenerator(train_images, train_masks, batch_size=49, augmentations=None, shuffle=False)\n",
        "images, masks = a.__getitem__(0)\n",
        "\n",
        "max_images = 49\n",
        "grid_width = 7\n",
        "grid_height = int(max_images / grid_width)\n",
        "fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width*2, grid_height*2))\n",
        "\n",
        "for i,(im, mask1) in enumerate(zip(images, masks)):\n",
        "    ax = axs[int(i / grid_width), i % grid_width]\n",
        "    ax.imshow(im)\n",
        "    ax.imshow(mask1.squeeze(), alpha=0.4)\n",
        "    ax.axis('off')\n",
        "\n",
        "print(mask1.shape)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FlbEECYeB4KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same tissue image with augmentations\n",
        "a = DataGenerator(train_images, train_masks, batch_size=49, augmentations=AUGMENTATIONS_TRAIN, shuffle=False)\n",
        "images, masks = a.__getitem__(0)\n",
        "\n",
        "max_images = 49\n",
        "grid_width = 7\n",
        "grid_height = int(max_images / grid_width)\n",
        "fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width*2, grid_height*2))\n",
        "\n",
        "for i,(im, mask1) in enumerate(zip(images, masks)):\n",
        "    ax = axs[int(i / grid_width), i % grid_width]\n",
        "    ax.imshow(im)\n",
        "    ax.imshow(mask1.squeeze(), alpha=0.4)\n",
        "    ax.axis('off')\n",
        "\n",
        "print(mask1.shape)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IGwmSl4uCCY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "id": "Gy4p-R_GCM_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = \"vgg19\"\n",
        "input_shape = (256, 256, 3)\n",
        "model = sm.Unet(\n",
        "             backbone_name=backbone,\n",
        "             input_shape=input_shape,\n",
        "             )"
      ],
      "metadata": {
        "id": "UbHUDhDiCkOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "4kOgW_ezCoQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "yFv34D7wCrMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, show_shapes=True, dpi=330, to_file=\"ÙStandardUnet.png\")"
      ],
      "metadata": {
        "id": "w66nV-C-CsiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "obbjGa5wC1A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/yingkaisha/keras-unet-collection\n",
        "!pip install keras_unet_collection"
      ],
      "metadata": {
        "id": "XlVzERSLC5X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_unet_collection import losses\n",
        "\n",
        "def binary_loss(y_true, y_pred):\n",
        "\n",
        "    loss_focal = losses.focal_tversky(y_true, y_pred, alpha=0.5, gamma=4/3)\n",
        "    loss_iou = losses.iou_seg(y_true, y_pred)\n",
        "    \n",
        "    # (x) \n",
        "    # loss_ssim = losses.ms_ssim(y_true, y_pred, max_val=1.0, filter_size=4)\n",
        "    \n",
        "    return loss_focal+loss_iou #+loss_ssim"
      ],
      "metadata": {
        "id": "Jk8D6vm8C8KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ],
      "metadata": {
        "id": "AzOORXHBC-a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(1e-4),\n",
        "              loss=binary_loss,\n",
        "              metrics=dice_coef)"
      ],
      "metadata": {
        "id": "DEIK5D41DBCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, Callback, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "import datetime\n",
        "\n",
        "from skimage import filters\n",
        "from scipy.ndimage import measurements\n",
        "from skimage.segmentation import watershed, mark_boundaries\n",
        "\n",
        "# Visualize training \n",
        "class loss_history(Callback):\n",
        "\n",
        "    def __init__(self, x=4):\n",
        "        self.x = x\n",
        "    \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        fig, ax = plt.subplots(1, 4, figsize=(18, 12))\n",
        "        [axi.set_axis_off() for axi in ax.ravel()]\n",
        "\n",
        "        ax[0].imshow(train_images[self.x])\n",
        "        ax[0].set_title(\"Tissue Image\")\n",
        "\n",
        "        ax[1].imshow(train_masks[self.x], cmap=\"gray\")\n",
        "        ax[1].set_title(\"Ground Truth\")\n",
        "\n",
        "        model_sample_input = train_images[self.x].astype(\"float32\") / 255.\n",
        "        preds_train = self.model.predict(np.expand_dims(model_sample_input, axis=0), verbose=0)\n",
        "        preds1 =  np.squeeze(preds_train[0]) >= 0.5\n",
        "        ax[2].imshow(preds1, cmap=\"gray\")\n",
        "        ax[2].set_title(\"Nuclei prediction\")\n",
        "\n",
        "        ax[3].imshow(mark_boundaries(train_images[self.x], preds1, color=(0, 0, 1)))\n",
        "        ax[3].set_title(\"Result\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "lr_scheduler = PolynomialDecay(\n",
        "    initial_learning_rate=1e-4,\n",
        "    end_learning_rate=1e-7,\n",
        "    decay_steps=40\n",
        ")\n",
        "\n",
        "# lr_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
        "#     1e-4, 100, alpha=0.0, name=None\n",
        "# )\n",
        "\n",
        "class ADJUSTLR(keras.callbacks.Callback):\n",
        "    def __init__ (self, model, freq, factor, verbose):\n",
        "        self.model=model\n",
        "        self.freq=freq\n",
        "        self.factor =factor\n",
        "        self.verbose=verbose\n",
        "        self.adj_epoch=freq\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch + 1 == self.adj_epoch: # adjust the learning rate\n",
        "            lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
        "            new_lr=lr * self.factor\n",
        "            self.adj_epoch +=self.freq\n",
        "            if self.verbose == 1:\n",
        "                print('\\non epoch ',epoch + 1, ' lr was adjusted from ', lr, ' to ', new_lr)\n",
        "            tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
        "\n",
        "\n",
        "create_path(\"logs/Unet\")\n",
        "csv_log = CSVLogger('logs/Unet/SimpleUnet_fold1_log00.csv', separator=',')\n",
        "model_name = f\"SimpleUnet_fold1_v00_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "create_path(\"models/Unet\")\n",
        "path_to_save_model = \"models/Unet/\" + model_name + \".h5\"\n",
        "checkpointer = ModelCheckpoint(path_to_save_model, verbose=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-7, verbose=1)\n",
        "# reduce_lr = LearningRateScheduler(schedule=lr_scheduler)\n",
        "early_stop   = EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True)\n",
        "\n",
        "print(model_name)"
      ],
      "metadata": {
        "id": "-xZBXpoODGDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "             loss_history(), \n",
        "             checkpointer, \n",
        "             reduce_lr, \n",
        "            #  csv_log, \n",
        "             early_stop\n",
        "             ]"
      ],
      "metadata": {
        "id": "OmiVC4mQDTp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "epochs = 120\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(train_images, train_masks, augmentations=AUGMENTATIONS_TRAIN, batch_size=batch_size)\n",
        "validation_generator = DataGenerator(val_images, val_masks, augmentations=AUGMENTATIONS_VAL, batch_size=batch_size)\n",
        "\n",
        "history = model.fit(training_generator,\n",
        "                    validation_data=validation_generator,                        \n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "WFOXEtF2DYVP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
